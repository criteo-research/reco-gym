{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install recogym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer's curse\n",
    "\n",
    "We will use the same likelihood model built in the previous notebook to showcase the optimizer's curse and how that can even lead to an inversion of arms (making a wrong decision).\n",
    "\n",
    "Let's first setup, as usual, the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.envs.session import OrganicSessions\n",
    "\n",
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "from recogym.evaluate_agent_sale import verify_agents, plot_verify_agents\n",
    "from recogym.envs.utils_sale import *\n",
    "\n",
    "import gym, recogym\n",
    "from copy import deepcopy\n",
    "from recogym import env_2_args\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 3]\n",
    "\n",
    "NUM_PRODUCTS = 10\n",
    "\n",
    "env_2_args['random_seed'] = 42\n",
    "env_2_args['num_products'] = NUM_PRODUCTS\n",
    "\n",
    "env = gym.make('reco-gym-v2')\n",
    "env.init_gym(env_2_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a logging policy that shows products with a probability proportional to their popularity (very plausible world model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_USERS = 1000\n",
    "\n",
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({\n",
    "           **organic_user_count_args,\n",
    "           **env_2_args,\n",
    "           'select_randomly': True,\n",
    "       }))\n",
    "\n",
    "popularity_policy_logs = env.generate_logs(NUM_USERS, organic_counter_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we use our product views feature provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents import FeatureProvider\n",
    "\n",
    "class CountFeatureProvider(FeatureProvider):\n",
    "    \"\"\"Feature provider as an abstract class that defined interface of setting/getting features\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(CountFeatureProvider, self).__init__(config)\n",
    "        self.feature_data = np.zeros((self.config.num_products))\n",
    "\n",
    "    def observe(self, observation):\n",
    "        \"\"\"Consider an Organic Event for a particular user\"\"\"\n",
    "        for session in observation.sessions():\n",
    "            self.feature_data[int(session['v'])] += 1\n",
    "\n",
    "    def features(self, observation):\n",
    "        \"\"\"Provide feature values adjusted to a particular feature set\"\"\"\n",
    "        return self.feature_data\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_data = np.zeros((self.config.num_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from recogym import Configuration, DefaultContext, Observation\n",
    "from recogym.envs.session import OrganicSessions\n",
    "\n",
    "\n",
    "def build_train_data(logs, feature_provider):\n",
    "    user_states, actions, rewards, proba_actions = [], [], [], []\n",
    "\n",
    "    current_user = None\n",
    "    for _, row in logs.iterrows():\n",
    "        if current_user != row['u']:\n",
    "            # User has changed: start a new session and reset user state.\n",
    "            current_user = row['u']\n",
    "            sessions = OrganicSessions()\n",
    "            feature_provider.reset()\n",
    "\n",
    "        context = DefaultContext(row['u'], row['t'])\n",
    "\n",
    "        if (row['z'] == 'organic') or (row['z'] == 'sale'):\n",
    "            sessions.next(context, row['v'])\n",
    "\n",
    "        else:\n",
    "            # For each bandit event, generate one observation for the user state, \n",
    "            # the taken action the obtained reward and the used probabilities.\n",
    "            feature_provider.observe(Observation(context, sessions))\n",
    "            user_states.append(feature_provider.features(None).copy())\n",
    "            actions.append(row['a'])\n",
    "            rewards.append(row['r'])\n",
    "            proba_actions.append(row['ps'])\n",
    "\n",
    "            # Start a new organic session.\n",
    "            sessions = OrganicSessions()\n",
    "    return np.array(user_states), np.array(actions).astype(int), np.array(rewards), np.array(proba_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now see data that will be provided to our agents based on logistic regressions.\n",
    "config = Configuration(env_2_args)\n",
    "count_feature_provider = CountFeatureProvider(config=config)\n",
    "\n",
    "user_states, actions, rewards, proba_actions = build_train_data(popularity_policy_logs, count_feature_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_start, preview_size = 500, 3\n",
    "\n",
    "print('user product views count at action time')\n",
    "print(user_states[preview_start:preview_start + preview_size])\n",
    "print('taken actions', actions[preview_start:preview_start + preview_size])\n",
    "print('obtained rewards', rewards[preview_start:preview_start + preview_size])\n",
    "print('probablities of the taken actions', proba_actions[preview_start:preview_start + preview_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodAgent(Agent):\n",
    "    def __init__(self, feature_provider, epsilon_greedy = False, epsilon = 0.3, seed=43):\n",
    "        self.feature_provider = feature_provider\n",
    "        self.random_state = RandomState(seed)\n",
    "        self.model = None\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        self.epsilon = epsilon\n",
    "        self.ctr = None\n",
    "        \n",
    "    @property\n",
    "    def num_products(self):\n",
    "        return self.feature_provider.config.num_products\n",
    "    \n",
    "    def _create_features(self, user_state, action):\n",
    "        \"\"\"Create the features that are used to estimate the expected reward from the user state\"\"\"\n",
    "        features = np.zeros(len(user_state) * self.num_products)\n",
    "        # perform kronecker product directly on the flattened version of the features matrix\n",
    "        features[action * len(user_state): (action + 1) * len(user_state)] = user_state\n",
    "        return features\n",
    "    \n",
    "    def train(self, logs):\n",
    "        user_states, actions, rewards, proba_actions = build_train_data(logs, self.feature_provider)\n",
    "        # Question 1 : estimate sales rate (boolean)\n",
    "        count_actions = np.unique(actions,return_counts = True)[1]\n",
    "        assert len(count_actions) == self.num_products\n",
    "        count_sales_bool = np.array([len(np.where((actions==_) & (rewards>0))[0]) for _ in range(self.num_products)])\n",
    "        self.salesrate = count_sales_bool / count_actions\n",
    "        print(\"Estimated sales rate : \",self.salesrate)\n",
    "        \n",
    "        features = np.vstack([\n",
    "            self._create_features(user_state, action) \n",
    "            for user_state, action in zip(user_states, actions)\n",
    "        ])\n",
    "        self.model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "        self.model.fit(features, rewards)\n",
    "    \n",
    "    def _score_products(self, user_state):\n",
    "        all_action_features = np.array([\n",
    "            # How do you create the features to feed the logistic model ?\n",
    "            self._create_features(user_state, action) for action in range(self.num_products)\n",
    "        ])\n",
    "        return self.model.predict_proba(all_action_features)[:, 1]\n",
    "        \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past history\"\"\"\n",
    "        self.feature_provider.observe(observation)        \n",
    "        user_state = self.feature_provider.features(observation)\n",
    "        \n",
    "        # Question 1.\n",
    "        # Insert code to evaluate the click through rate of every action\n",
    "        \n",
    "        # Question 2.\n",
    "        # Why do we set the propsity score to 1.0?\n",
    "        # Answer : we use historical data (we sample from the initial policy \\Pi_0) and build a supervized-like model to fit the data\n",
    "        \n",
    "        # Question 3.\n",
    "        # How would you implement epsilong greedy?\n",
    "        if (self.epsilon_greedy == True) & (np.random.rand() < self.epsilon) : \n",
    "            print(\"Explore\")\n",
    "            action = np.random.randint(self.num_products())\n",
    "        else :\n",
    "            action = np.argmax(self._score_products(user_state))\n",
    "        \n",
    "        ps = 1.0\n",
    "        all_ps = np.zeros(self.num_products)\n",
    "        all_ps[action] = 1.0        \n",
    "        \n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': ps,\n",
    "                'ps-a': all_ps,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_provider.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(env, num_users, agent):\n",
    "    \"\"\"Small utility function to collect stats about your agent on simulated test traffic\n",
    "    It is really recogym specific, you do not need to look at its internal details\n",
    "    \"\"\"\n",
    "    env = deepcopy(env)\n",
    "    env.agent = agent  \n",
    "    \n",
    "    events = []\n",
    "    for user_id in range(num_users):\n",
    "        env.reset(user_id)\n",
    "        observation, reward, done, _ = env.step(None)\n",
    "\n",
    "        while not done:\n",
    "            for session in observation.sessions():\n",
    "                events += [{**session, 'z': 'organic'}]\n",
    "\n",
    "            action, observation, reward, done, info = env.step_offline(observation, reward, done)\n",
    "            events += [{**action, 'z': 'bandit', 'c': info['click'],'r': reward}]\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    events_df = pd.DataFrame().from_dict(events)\n",
    "    ordered_cols = ['t', 'u', 'z', 'v', 'a', 'c', 'r', 'ps', 'ps-a']\n",
    "    all_cols = ordered_cols + [col for col in events_df.columns if col not in ordered_cols]\n",
    "    return events_df[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the feature vector used by the Likelihood agent.\n",
    "picked_sample = 500\n",
    "\n",
    "count_product_views_feature_provider = CountFeatureProvider(config)\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider)\n",
    "\n",
    "print('User state: ', user_states[picked_sample])\n",
    "print('Action: ', actions[picked_sample])\n",
    "print('Created cross features: ')\n",
    "print(likelihood_logreg._create_features(user_states[picked_sample], actions[picked_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider, use_argmax=True)\n",
    "likelihood_logreg.train(popularity_policy_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_users = 1000\n",
    "likelihood_logreg_test_logs = run_agent(env, n_test_users, likelihood_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_logreg_test_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the predicted number of clicks vs. the actual number\n",
    "\n",
    "We can see that the model over-predicted the number of clicks, and even inversed the order of products 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# To force the arms to share the same colors\n",
    "palette = {c: f'C{c}' for c in range(NUM_PRODUCTS)} if NUM_PRODUCTS < 20 else None\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4), sharey=True)\n",
    "sns.barplot(x=\"a\", y=\"expected-value\", data=likelihood_logreg_test_logs, ax=axes[0], estimator=sum, palette=palette)\n",
    "axes[0].set_title('Expected number of sales')\n",
    "axes[0].set_xlabel('Selected product')\n",
    "\n",
    "sns.barplot(x=\"a\", y=\"c\", data=likelihood_logreg_test_logs, ax=axes[1], estimator=sum, palette=palette)\n",
    "axes[1].set_title('Obtained number of sales')\n",
    "axes[1].set_xlabel('Selected product')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
